# Source 配置(目前支持 csv, txt, orc, parquet, hive)
source.type=txt
source.path=hdfs://172.27.128.2:8020/user/xiaoxue/guangfa/user_detail
## 文本(txt, csv)引入其他配置
source.firstLine.schema=false
source.line.delimiter=\n
source.field.delimiter=,
source.charset=UTF-8

## 文本引入类型配置(默认流式)
## 根据提供的 watchType(PROCESS_CONTINUOUSLY, PROCESS_ONCE),这个 source 可以定期（每隔 interval 毫秒）监测给定路径的新数据
source.watch.type=PROCESS_CONTINUOUSLY
## default 10s
source.watch.interval=60000

# sink 配置(目前只支持 kafka)
sink.kafka.version=0.11
#sink.kafka.brokers=172.27.130.144:9092,172.27.130.145:9092,172.27.130.146:9092
sink.kafka.brokers=172.27.137.231:9092
sink.kafka.topic=lyh_local_sink_exactly_once_1
#sink.kafka.topic=lyh_local_sink_at_least_once

hadoop.user.name=work
hadoop.home.dir=hadoop/cdh

stream.checkpoint.enable=true
stream.checkpoint.mode=EXACTLY_ONCE
#stream.checkpoint.mode=AT_LEAST_ONCE
#stream.checkpoint.dir=file:///tmp/checkpoints
stream.checkpoint.dir=hdfs://172.27.128.2:8020/tmp/lyh/checkpoints
stream.checkpoint.interval=60000
stream.checkpoint.timeout=600000
stream.checkpoint.min.pause=60000
stream.checkpoint.tolerable.failure.num=2
# https://my.oschina.net/u/134474/blog/1531556
sink.kafka.request.timeout.ms=180000
