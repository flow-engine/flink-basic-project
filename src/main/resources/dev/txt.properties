# Source 配置(目前支持 csv, txt, orc, parquet, hive)
source.type=txt
#source.path=hdfs://m7-common-cdh02:8020/user/liyihui/csv
source.path=file:///Users/liyihui/Downloads/data/txt
## 文本(txt, csv)引入其他配置
source.firstLine.schema=false
source.line.delimiter=\n
source.field.delimiter=,
source.charset=UTF-8

## 文本引入类型配置(默认流式)
## 根据提供的 watchType(PROCESS_CONTINUOUSLY, PROCESS_ONCE),这个 source 可以定期（每隔 interval 毫秒）监测给定路径的新数据
source.watch.type=PROCESS_CONTINUOUSLY
## default 10s
source.watch.interval=60000

# sink 配置(目前只支持 kafka)
sink.kafka.version=0.11
sink.kafka.brokers=172.27.137.231:9092
sink.kafka.topic=lyh-sink

hadoop.user.name=work
hadoop.home.dir=hadoop/cdh

stream.checkpoint.enable=false
## merge (BO 表)
#sink.merge.enable=true
### 默认 merge 到 feat 字段中(除了 id)
#sink.merge.nested.field=feas
### 默认 id 排除 merge, 保持原样
#sink.merge.exclude.fields=col_1
