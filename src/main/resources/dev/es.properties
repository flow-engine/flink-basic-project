stream.checkpoint.enable=false

## 文本引入类型配置(默认流式)
## 根据提供的 watchType(PROCESS_CONTINUOUSLY, PROCESS_ONCE),这个 source 可以定期（每隔 interval 毫秒）监测给定路径的新数据
source.watch.type=PROCESS_ONCE
source.watch.interval=60

# Source 配置(目前支持 csv, txt, orc, parquet, hive)
hadoop.user.name=work
hadoop.home.dir=hadoop/cdh

source.type=parquet
sink.es.sync.type=full
source.path=hdfs://m7-common-cdh07:8020/prophet/autoui/382cdh/workspace/cdh1/telamon/1/lyh-flink/finite_table
#source.path=hdfs://m7-common-cdh07:8020/user/liyihui/es/full_1
#source.path=hdfs://m7-common-cdh07:8020/user/liyihui/es/full_0

#sink.es.sync.type=incremental
#source.path=hdfs://m7-common-cdh07:8020/user/liyihui/es/incremental

#sink.es.sync.type=finite
#source.path=hdfs://m7-common-cdh07:8020/user/liyihui/es/finite

sink.type=es
sink.es.server=172.27.14.125:9200
sink.es.index=lyh_config
sink.es.type=parquet
sink.es.unique.column=id
sink.es.version.column=version
sink.es.version=1586959593

#stream.sql.schema=struct<city:String,name:String,x:String,y:String,tags:String,id:Int>
stream.sql.enable=true
stream.sql.schema.json={"city": "String", "name": "String", "x": "String", "y": "String", "tags": "String", "id": "Int"}
stream.sql=select id, city, name, concat(x,'-', y) as location, arraySplit(tags, '|') as tags from t1