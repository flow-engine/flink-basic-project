## 文本(txt, csv)引入其他配置
source.firstLine.schema=false
source.line.delimiter=\n
source.field.delimiter=,
source.charset=UTF-8

## 文本引入类型配置(默认流式)
## 根据提供的 watchType(PROCESS_CONTINUOUSLY, PROCESS_ONCE),这个 source 可以定期（每隔 interval 毫秒）监测给定路径的新数据
source.watch.type=PROCESS_CONTINUOUSLY
## default 10s
source.watch.interval=60000

## Hive 引入配置(CDH)
#source.type=jdbc
source.db.type=hive
source.db.driverClassName=org.apache.hive.jdbc.HiveDriver

# sink 配置(目前只支持 kafka)
sink.kafka.version=0.11
#source.type=kafka
source.kafka.version=0.11

# ck
stream.checkpoint.enable=true
stream.checkpoint.type=rocksdb
stream.checkpoint.dir=hdfs:///tmp/csp/flink/checkpoints

# merge (BO 表)
sink.merge.enable=false
## 默认 merge 到 feat 字段中(除了 id)
sink.merge.nested.field=feas
## 默认 id 排除 merge, 保持原样
sink.merge.exclude.fields=id

#sql
stream.sql.enable=false